{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #                             BOOK RECOMMENDATION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING AND EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Description</th>\n",
       "      <th>Category</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Price Starting With ($)</th>\n",
       "      <th>Publish Date (Month)</th>\n",
       "      <th>Publish Date (Year)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goat Brothers</td>\n",
       "      <td>By Colton, Larry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>History , General</td>\n",
       "      <td>Doubleday</td>\n",
       "      <td>8.79</td>\n",
       "      <td>January</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Missing Person</td>\n",
       "      <td>By Grumbach, Doris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fiction , General</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>4.99</td>\n",
       "      <td>March</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't Eat Your Heart Out Cookbook</td>\n",
       "      <td>By Piscatella, Joseph C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooking , Reference</td>\n",
       "      <td>Workman Pub Co</td>\n",
       "      <td>4.99</td>\n",
       "      <td>September</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When Your Corporate Umbrella Begins to Leak: A...</td>\n",
       "      <td>By Davis, Paul D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natl Pr Books</td>\n",
       "      <td>4.99</td>\n",
       "      <td>April</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Spangler's Breastfeeding : A Parent's Guide</td>\n",
       "      <td>By Spangler, Amy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amy Spangler</td>\n",
       "      <td>5.32</td>\n",
       "      <td>February</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Foundation of Leadership: Enduring Princip...</td>\n",
       "      <td>By Short, Bo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excalibur Press</td>\n",
       "      <td>6.06</td>\n",
       "      <td>January</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chicken Soup for the Soul: 101 Stories to Open...</td>\n",
       "      <td>By Canfield, Jack (COM) and Hansen, Mark Victo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-help , Personal Growth , Self-Esteem</td>\n",
       "      <td>Health Communications Inc</td>\n",
       "      <td>4.99</td>\n",
       "      <td>May</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Journey Through Heartsongs</td>\n",
       "      <td>By Stepanek, Mattie J. T.</td>\n",
       "      <td>Collects poems written by the eleven-year-old ...</td>\n",
       "      <td>Poetry , General</td>\n",
       "      <td>VSP Books</td>\n",
       "      <td>19.96</td>\n",
       "      <td>September</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In Search of Melancholy Baby</td>\n",
       "      <td>By Aksyonov, Vassily, Heim, Michael Henry, and...</td>\n",
       "      <td>The Russian author offers an affectionate chro...</td>\n",
       "      <td>Biography &amp; Autobiography , General</td>\n",
       "      <td>Random House</td>\n",
       "      <td>4.99</td>\n",
       "      <td>June</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Christmas Cookies</td>\n",
       "      <td>By Eakin, Katherine M. and Deaman, Joane (EDT)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooking , General</td>\n",
       "      <td>Oxmoor House</td>\n",
       "      <td>12.98</td>\n",
       "      <td>June</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                      Goat Brothers   \n",
       "1                                 The Missing Person   \n",
       "2                  Don't Eat Your Heart Out Cookbook   \n",
       "3  When Your Corporate Umbrella Begins to Leak: A...   \n",
       "4    Amy Spangler's Breastfeeding : A Parent's Guide   \n",
       "5  The Foundation of Leadership: Enduring Princip...   \n",
       "6  Chicken Soup for the Soul: 101 Stories to Open...   \n",
       "7                         Journey Through Heartsongs   \n",
       "8                       In Search of Melancholy Baby   \n",
       "9                                  Christmas Cookies   \n",
       "\n",
       "                                             Authors  \\\n",
       "0                                   By Colton, Larry   \n",
       "1                                 By Grumbach, Doris   \n",
       "2                           By Piscatella, Joseph C.   \n",
       "3                                  By Davis, Paul D.   \n",
       "4                                   By Spangler, Amy   \n",
       "5                                       By Short, Bo   \n",
       "6  By Canfield, Jack (COM) and Hansen, Mark Victo...   \n",
       "7                          By Stepanek, Mattie J. T.   \n",
       "8  By Aksyonov, Vassily, Heim, Michael Henry, and...   \n",
       "9     By Eakin, Katherine M. and Deaman, Joane (EDT)   \n",
       "\n",
       "                                         Description  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7  Collects poems written by the eleven-year-old ...   \n",
       "8  The Russian author offers an affectionate chro...   \n",
       "9                                                NaN   \n",
       "\n",
       "                                     Category                  Publisher  \\\n",
       "0                           History , General                  Doubleday   \n",
       "1                           Fiction , General           Putnam Pub Group   \n",
       "2                         Cooking , Reference             Workman Pub Co   \n",
       "3                                         NaN              Natl Pr Books   \n",
       "4                                         NaN               Amy Spangler   \n",
       "5                                         NaN            Excalibur Press   \n",
       "6   Self-help , Personal Growth , Self-Esteem  Health Communications Inc   \n",
       "7                            Poetry , General                  VSP Books   \n",
       "8         Biography & Autobiography , General               Random House   \n",
       "9                           Cooking , General               Oxmoor House   \n",
       "\n",
       "   Price Starting With ($) Publish Date (Month)  Publish Date (Year)  \n",
       "0                     8.79              January                 1993  \n",
       "1                     4.99                March                 1981  \n",
       "2                     4.99            September                 1983  \n",
       "3                     4.99                April                 1991  \n",
       "4                     5.32             February                 1997  \n",
       "5                     6.06              January                 1997  \n",
       "6                     4.99                  May                 1993  \n",
       "7                    19.96            September                 2001  \n",
       "8                     4.99                 June                 1987  \n",
       "9                    12.98                 June                 1986  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('BooksDatasetClean.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                          0\n",
       "Authors                        0\n",
       "Description                32859\n",
       "Category                   26161\n",
       "Publisher                      8\n",
       "Price Starting With ($)        0\n",
       "Publish Date (Month)           0\n",
       "Publish Date (Year)            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fiction , General</th>\n",
       "      <td>2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction , Literary</th>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction , Mystery &amp; Detective , General</th>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction , Thrillers , General</th>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiction , Romance , Contemporary</th>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature , Ecosystems &amp; Habitats , Mountains</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language Arts &amp; Disciplines , Etymology</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religion , Antiquities &amp; Archaeology</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Law , Legal Education</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Young Adult Nonfiction , Biography &amp; Autobiography , Science &amp; Technology</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3106 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "Category                                                 \n",
       " Fiction , General                                   2549\n",
       " Fiction , Literary                                  1709\n",
       " Fiction , Mystery & Detective , General             1690\n",
       " Fiction , Thrillers , General                       1115\n",
       " Fiction , Romance , Contemporary                    1074\n",
       "...                                                   ...\n",
       " Nature , Ecosystems & Habitats , Mountains             1\n",
       " Language Arts & Disciplines , Etymology                1\n",
       " Religion , Antiquities & Archaeology                   1\n",
       " Law , Legal Education                                  1\n",
       " Young Adult Nonfiction , Biography & Autobiogr...      1\n",
       "\n",
       "[3106 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df['Category'].value_counts())\n",
    "#2938 unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Authors</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>By</th>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Roberts, Nora</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Time-Life Books</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By unknown</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By \"Better Homes and Gardens\"</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Chan, Kit</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By McCannon, John and Jordan, Pam</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Pettit, Stephen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Shone, Rob (ILT), Royston, Angela, and Forsey, Chris (ILT)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>By Carpentier, Marcel</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63570 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "Authors                                                  \n",
       "By                                                   1043\n",
       "By Roberts, Nora                                      195\n",
       "By Time-Life Books                                    172\n",
       "By unknown                                            122\n",
       "By \"Better Homes and Gardens\"                         121\n",
       "...                                                   ...\n",
       "By Chan, Kit                                            1\n",
       "By McCannon, John and Jordan, Pam                       1\n",
       "By Pettit, Stephen                                      1\n",
       "By Shone, Rob (ILT), Royston, Angela, and Forse...      1\n",
       "By Carpentier, Marcel                                   1\n",
       "\n",
       "[63570 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df['Authors'].value_counts())\n",
    "#39279 unique authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('merged_books_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews Dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65296 entries, 7 to 103062\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Title                    65296 non-null  object \n",
      " 1   Authors                  65296 non-null  object \n",
      " 2   Description              65296 non-null  object \n",
      " 3   Category                 65296 non-null  object \n",
      " 4   Publisher                65296 non-null  object \n",
      " 5   Price Starting With ($)  65296 non-null  float64\n",
      " 6   Publish Date (Month)     65296 non-null  object \n",
      " 7   Publish Date (Year)      65296 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 4.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Explore the books dataset\n",
    "print(\"Reviews Dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                      0\n",
       "Authors                    0\n",
       "Description                0\n",
       "Category                   0\n",
       "Publisher                  0\n",
       "Price Starting With ($)    0\n",
       "Publish Date (Month)       0\n",
       "Publish Date (Year)        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING USING SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: @#$ i love pancakes and honey\n",
      "Preprocessed Text:  love pancake honey\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load the English tokenizer, tagger, parser, and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner'])  # Disabling Named Entity Recognition for faster processing\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Parse the text using SpaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Lemmatize and remove stopwords and special characters\n",
    "    preprocessed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space and not token.is_digit]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(preprocessed_tokens)\n",
    "    \n",
    "    # Remove remaining special characters using regex\n",
    "    preprocessed_text = re.sub(r'[^a-zA-Z\\s]', '', preprocessed_text)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Example usage:\n",
    "text = \"@#$ i love pancakes and honey\"\n",
    "preprocessed_text = preprocess_text(text)\n",
    "print(\"Original Text:\", text)\n",
    "print(\"Preprocessed Text:\", preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING A WORD SOUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Load the dataset containing information about books\n",
    "books_df = pd.read_csv('merged_books_clean.csv')\n",
    "\n",
    "# Apply preprocessing to all textual features\n",
    "text_features = ['Category','Authors','Title']\n",
    "for feature in text_features:\n",
    "    books_df[feature] = books_df[feature].fillna('').apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Journey heartsong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Search Melancholy Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dieter Guide Weight Loss sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germ Biological Weapons America Secret War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good Book read Bible Mind heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shoutin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hill Rat blow Lid Congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>personality cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Betrayal Clinton Administration Undermined Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shadow Song</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title\n",
       "0                                  Journey heartsong\n",
       "1                             Search Melancholy Baby\n",
       "2                       Dieter Guide Weight Loss sex\n",
       "3         germ Biological Weapons America Secret War\n",
       "4                    Good Book read Bible Mind heart\n",
       "5                                            shoutin\n",
       "6                         Hill Rat blow Lid Congress\n",
       "7                                    personality cat\n",
       "8  Betrayal Clinton Administration Undermined Ame...\n",
       "9                                        Shadow Song"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(books_df[feature]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "# Combine all textual features into a single feature\n",
    "books_df['combined_text'] =books_df['Category'] + ' ' + books_df['Authors'] \n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 10000\n",
    "\n",
    "# Initialize an empty array to store the similarity scores\n",
    "similarity_scores = []\n",
    "\n",
    "# Initialize variable to keep track of maximum number of features\n",
    "max_features = 0\n",
    "\n",
    "# Iterate over the dataset in chunks\n",
    "for i in range(0, len(books_df), chunk_size):\n",
    "    # Extract chunk of data\n",
    "    chunk = books_df['combined_text'][i:i+chunk_size].tolist()\n",
    "\n",
    "    # Use TF-IDF vectorization to convert textual features into numerical representations\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    combined_tfidf = tfidf_vectorizer.fit_transform(chunk)\n",
    "\n",
    "    # Keep track of maximum number of features\n",
    "    max_features = max(max_features, combined_tfidf.shape[1])\n",
    "\n",
    "    # Calculate similarity scores within the chunk\n",
    "    chunk_similarity_matrix = cosine_similarity(combined_tfidf, combined_tfidf)\n",
    "    \n",
    "    # Append similarity scores to the list\n",
    "    similarity_scores.append(chunk_similarity_matrix)\n",
    "\n",
    "# Pad smaller chunks with zeros along dimension 1\n",
    "for i in range(len(similarity_scores)):\n",
    "    if similarity_scores[i].shape[1] < max_features:\n",
    "        pad_width = ((0, 0), (0, max_features - similarity_scores[i].shape[1]))\n",
    "        similarity_scores[i] = np.pad(similarity_scores[i], pad_width, mode='constant')\n",
    "\n",
    "# Concatenate similarity scores from all chunks\n",
    "similarity_matrix = np.concatenate(similarity_scores, axis=0)\n",
    "np.save('similarity_matrix.npy', similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## content based recommendation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Title      Authors\n",
      "35617                   Baby Bear Treasury Stories young             \n",
      "34638                                       Children Men    James P D\n",
      "4168                         Imzadi Star Trek generation  David Peter\n",
      "19276  restoration Star Trek New Frontier Excalibur Book  David Peter\n",
      "44791                   fire High Star Trek New Frontier  David Peter\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Implement a function to recommend similar items based on user input\n",
    "def recommend_books_based_on_input(user_input, similarity_matrix, books_df, top_n=5):\n",
    "    # Preprocess user input\n",
    "    user_input = preprocess_text(user_input)\n",
    "\n",
    "    # Find the index of the book that matches the user input\n",
    "    matching_indices = books_df.index[books_df['combined_text'].str.contains(user_input, case=False)]\n",
    "\n",
    "    # Calculate the average similarity scores for matching books\n",
    "    average_similarity_scores = []\n",
    "    for idx in matching_indices:\n",
    "        similarity_scores = similarity_matrix[idx]\n",
    "        average_similarity_scores.append(sum(similarity_scores) / len(similarity_scores))\n",
    "\n",
    "    # Sort matching books by average similarity scores\n",
    "    sorted_indices = [x for _, x in sorted(zip(average_similarity_scores, matching_indices), reverse=True)]\n",
    "\n",
    "    # Recommend top N similar books\n",
    "    recommended_books = books_df.iloc[sorted_indices[:top_n]]\n",
    "    return recommended_books[['Title', 'Authors']]\n",
    "\n",
    "\n",
    "user_input = input(\"Please enter a keyword or phrase: \")\n",
    "recommended_books = recommend_books_based_on_input(user_input, similarity_matrix, books_df)\n",
    "print(recommended_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, save other necessary data\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "np.save('similarity_matrix.npy', similarity_matrix)\n",
    "books_df.to_csv('books_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
